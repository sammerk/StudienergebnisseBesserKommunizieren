---
title: Evidenz.Besser.Kommunizieren.
subtitle: Wie Bildungswissenschaften und Fachdidaktiken ihre Wissenschaftskommunikation weiterentwickeln kÃ¶nnen.
shorttitle: Evidenz.Besser.Kommunizieren.
author:
  - name: Samuel Merk
    corresponding: true
    orcid: 0000-0003-2594-5337
    email: merk@ph-karlsruhe.de
    roles:
      - conceptualization
      - data curation
      - formal Analysis
      - investigation
      - methodology
      - software
      - supervision
      - validation
      - visualization
      - writing inital draft
      - editing
    affiliations:
      - id: id1
        name: "PÃ¤dagogische Hochschule Karlsruhe"
        address: BismarckstraÃŸe 10
        city: Karlsruhe
        country: Germany
        postal-code: 76133
  - name: Sarah Bez
    affiliations:
      - id: id1
  - name: Kirstin Schmidt
    affiliations:
      - id: id1
author-note:
  disclosures:
    data-sharing: Die Daten dieses Artikels sind zu finden unter
    conflict-of-interest: Die Autor\:innen haben keine Interessenskonflikte zu berichten
abstract: "LehrkrÃ¤fte treffen tagtÃ¤glich unzÃ¤hlige Entscheidungen bzgl. ihrer Unterrichtsgestaltung und -entwicklung<!-- SB: Sonst eher immer Schul- und Unterrichtsentwicklung genannt und daher hier evtl auch?-->. Dabei rekurrieren sie vornehmlich auf persÃ¶nliche Erfahrung, Konzeptwissen oder Heuristiken. Evidenz aus Bildungswissenschaften und Fachdidaktiken wird das Potenzial zugeschrieben, diese Entscheidungsprozesse ergÃ¤nzend <!-- SB: komplementÃ¤r ist nach meiner Auffassung eher dichotom im Sinne von gegensÃ¤tzlich, vielleicht eher: ergÃ¤nzend? Dann weniger gegensÃ¤tzlich, aber nur, wenn man das auch so meint :-)--> zu informieren und zu objektivieren. Dazu ist es jedoch notwendig, dass die betroffenen LehrkrÃ¤fte diese Evidenz nicht fehlinterpretieren, was wiederum entsprechende Kompetenzen der LehrkrÃ¤fte oder besonders geschickte <!-- gelungene?--> Wissenschaftkommunikation voraussetzt. Der vorliegende Beitrag untersucht daher die MÃ¶glichkeiten und Grenzen der Kommunikation von EffektstÃ¤rken an Lehramtsstudierende am Beispiel des sog. zweiten PISA-Schocks <!-- SB: diese Formulierung kommt spÃ¤ter nicht mehr und wird daher auch nicht weiter eingeordnet. WÃ¼rde daher hier vielleicht eher schreiben: am Beispiel der letzten PISA-Ergebnisse oder so-->. Im Ergebniss zeigt sich, dass Lehramtsstudierende EffektstÃ¤rken sehr ungenau (Noise) ein- und im Mittel drastisch Ã¼berschÃ¤tzen (Practical Significance Bias). Dieser Bias konnte durch die Verwendung alternativer Visualisierungen deutlich eingedÃ¤mmt <!-- SB: finde diese Formulierung eher wertend und relativ stark :-) vielleicht eher: verringert oder vermindert?--> werden $(d = .5)$"
# Put as many keywords at you like, separated by commmas (e.g., [reliability, validity, generalizability])
keywords: [Lehrpersonenprofessionalisierung, Wissenschaftskommunikation, Practical Significance Bias]
# If true, tables and figures are mingled with the text instead of listed at the end of the document.
floatsintext: true
# Numbered lines (.pdf and .docx only)
numbered-lines: false
# File with references
bibliography: references.bib
# Suppress title page
suppress-title-page: false
# Link citations to references
link-citations: true
notebook-links: true
lang: de
---

<!-- Max. 35k inklusive allem-->
<!-- SB: noch zu den Keywords: hÃ¤tte hier noch evidence-informed practice o.Ã¤. erwartet. WÃ¼rde mich interessieren, warum Du das bewusst weggelassen hast?--> 
Die bildungswissenschaftliche Literatur zu Schul- und Unterrichtsentwicklung bedient sich einer Vielzahl theoretischer Grundlegungen [@bohl2020] und blickt daher aus ganz verschiedenen Winkeln auf diesen Gegenstand: Neben eher systemtheoretischen Perspektiven [@bauer1978] finden sich u.a. AnsÃ¤tze mit Entlehnungen aus der Lehr-Lern- [@helmke2022] und Organisationspsychologie [@holtappels2007] oder mit dem Leitgedanken der Praxisorientierung [@bruegelmann2018]. Datenbasierte Schulentwicklung <!-- SB: siehe Abstract: eher Datenbasierte Schul- und Unterrichtsentwicklung?--> hat im deutschsprachigen Raum erst in den vergangenen zwei Dekaden Momentum gefunden <!-- SB: Momentum gefunden ist fÃ¼r mich keine gelÃ¤ufige Formulierung. Vielleicht: ist aufgekommen; hat Eingang gefunden o.Ã¤.--> , wenngleich deren Grundidee des empirischen Einholens von Information Ã¼ber den Ist-Stand schon zuvor gefordert und auch umgesetzt wurde [@altrichter2006]. In jÃ¼ngerer Zeit ist jedoch von inner- wie auÃŸerwissenschaftlichen Stakeholdern vermehrt die Forderung nach einer Entwicklung von Schule und Unterricht hÃ¶rbar geworden, die ihre Entscheidungen durch Evidenz informiert [@aero2023; @bauer2012; @eurlex2024; @pellegrini2021; @slavin2020]. Da jedoch einerseits die Genese und Interpretation von Evidenz nicht zu den professionellen Kernkompetenzen von LehrkÃ¤ften gehÃ¶rt und andererseits Bildungswissenschaftler- und Fachdidaktiker:innen keine Expert:innen fÃ¼r die Gestaltung von Schule und Unterricht sind, plÃ¤diert der vorliegende Beitrag dafÃ¼r, Wissenschaftskommunikation erstens als dialogischen Prozess zwischen Bildungswissenschaften/Fachdidaktiken und LehrkrÃ¤ften aufzufassen <!-- darauf bist du im Theorieteil nicht nÃ¤her eingegangen; kommt aber ja vielleicht in der Diskussion? GUTER PUNKT! KOMMT IN DIE DISKUSSION |SB: Ja, das wird bisher noch nicht eingelÃ¶st, ist mir auch aufgefallen--> und zweitens diesen forschungsbasiert weiter zu entwickeln.

Daher fÃ¼hrt der folgende theoretische Hintergrund zunÃ¤chst in Konzepte und Begriffe evidenzinformierter Praxis ein, bevor er auf Wissenschaftskommunikation in Bildungswissenschaften und Fachdidaktiken eingeht, um abschlieÃŸend ein empirisches Beispiel zu skizzieren.

# Theoretischer Hintergrund

## Evidenzinformiertes Handeln

### Was kann unter Â»EvidenzÂ« verstanden werden?

Etymologisch kann Â»EvidenzÂ« als Substantivierung des Adjektivs Â»evidentÂ« gesehen werden [@kluge2011, S.263], welches wiederum im 18. Jahrhundert dem lateinischen Â»evidensÂ« [Â»ersichtlich, augenscheinlichÂ«, @hau2012] entlehnt wurde [@stark2017]. Allerdings meinen Bildungswissenschaftler:innen und Fachdidaktiker:innen gerade nicht Â»das AugenscheinlicheÂ« oder Â»das direkt ErsichtlicheÂ«, wenn sie von Evidenz sprechen. Vielmehr ist in DefinitionsvorschlÃ¤gen von Â»wissenschaftlichem WissenÂ« [@stark2017] von einer Â»FunktionÂ« von Daten fÃ¼r die BestÃ¤tigung oder Widerlegung von Hypothesen und Theorien [@bromme2014b] oder von Â»warrants for making assertions or knowledge claimsÂ« [@shavelson2002] die Rede. In einer aktuellen Systematisierung verschiedener VerstÃ¤ndnisse des Evidenz-Begriffs in den Bildungswissenschaften hebt Schmidt [-@schmidt2024] hervor, dass nur wenige Definitionen ausschlieÃŸlich quantitativer Empirie die MÃ¶glichkeit zuschreiben, Evidenz zu generieren, sondern meistens auch qualitative Empirie, Theorien sowie mathematische und logische Analysen als potenziell evidenzgenerierend definiert werden. Insbesondere die Inklusion nicht-empirischer EntitÃ¤ten wie Â»TheorienÂ« oder Â»logische AnalysenÂ« mÃ¶gen auf den ersten Blick widersprÃ¼chlich wirken, da der Begriff Evidenz insbesondere im deutschsprachigen Raum teils mit Ergebnissen explanativer quantitativer Studien assoziiert scheint <!-- SB: Das ist zwar vorsichtig formuliert, aber ein, zwei Belege/Beispiele fÃ¼r diesen Claim einzufÃ¼gen, wÃ¤re Ã¼berlegenswert.-->  Dieser scheinbare Widerspruch wirkt jedoch weniger stark, wenn man berÃ¼cksichtigt, dass insbesondere in der Lehr-Lernforschung mit Â»TheorienÂ« wohl eher sogenannte Â»tried-and-tested theoriesÂ« [@renkl2022] gemeint sein dÃ¼rften. Diese stellen eher Rahmenmodelle oder sogenannte Â»interventional modelsÂ« (z.B. Cognitive Theory of Multi-Media Learning) dar (ebd.), die wiederum meist stark von empirischen Ergebnissen beeinflusst sind. Daher ist es plausibel, Â»TheorienÂ« die Funktion als Â»warrantÂ« fÃ¼r Â»knowledge claimsÂ« zuzuschreiben und sie also auch als Â»EvidenzÂ« zu bezeichnen. <!-- Diese stellen eher Rahmenmodelle oder sogenannte Â»interventional modelsÂ« (z.B. Cognitive Theory of Multi-Media Learning) dar (ebd.). Da solche Â»TheorienÂ« wiederum meist stark von empirischen Ergebnissen beeinflusst sind, ist es plausibel ihnen die Funktion als Â»warrantÂ« fÃ¼r Â»knowledge claimsÂ« zuzuschreiben - sie also auch als Â»EvidenzÂ« zu bezeichnen. -->

### Evidenzbasiert, evidenzinformiert, evidenzorientiert. 
<!-- SB: warum hier Punkt am Ende?-->
<!-- Evidenzinformiert, evidenzorientiert, evidenzbasiert. vielleicht umstellen, dass es zur Kapitelstruktur passt ? -->

Im vorigen Abschnitt wurde deutlich, dass Â»EvidenzÂ« ein uneinheitlich gebrauchter und gleichermaÃŸen komplex wie unscharf definierter Begriff ist. Im Lichte dessen erscheint es nur konsequent, dass auch die Begriffe evidenzbasiert, evidenzinformiert, evidenzorientiert, datenbasiert, forschungsbasiert und forschungsinformiert klassisches *Jingle and Jangle* [@thorndike1904; @kelly2023] darstellen<!-- SB: vielleicht eher: als Jingle and Jangle einzuordnen sind; finde die bisherige Formulierung eher untypisch-->. D.h., dass also unterschiedliche Begriffe fÃ¼r das Gleiche und gleiche Begriffe fÃ¼r Unterschiedliches gebraucht werden. Die Differenzen zwischen evidenz**basiert** und evidenz**informiert** sowie evidenz**orientiert** <!-- korrekterweise zwischen evidenzbasiert und evidenzinformiert sowie evidenzorientiert, oder VERSTEH ICH NOCH NICHT--> kÃ¶nnen jedoch auch bedeutsam interpretiert werden: Da mit Â»Evidenz**basierung**Â« oft Â»the medical modelÂ« [@jones2024] und damit Evidenz aus *Kontrollgruppenexperimenten* als *notwendige Voraussetzung* fÃ¼r eine Entscheidung assoziiert wird, zieht dieser Begriff die stÃ¤rkste Kritik auf sich [@bellmann2011; @biesta2007]. Den Begriffen Â»evidenz**orientiert**Â« und Â»evidenz**informiert**Â« wird mit weniger Fundamentalkritik begegnet, da diese schon rein sprachlich eher eine heuristische denn eine rechenschaftslegende Rolle impliziert. <!-- @Sarah: Ist der Satz so verstÃ¤ndlich? SB: nein, ich bin in diesem Absatz und auch beim letzten Satz nicht ganz mitgekommen. Ich versuche, das zu formulieren: 
1.) Oben werden nicht nur evidenzinformiert/orientiert/basiert sondern auch daten..., forschungs... aufgefÃ¼hrt, aber dann nicht mehr darauf eingegangen. Hier werden die Lesenden im Unklaren gelassen. 
2.) Die Kriterien von ei, eo und eb fÃ¼r die Unterscheidung werden anhand der Formulierungen nicht klar: evidenzbasiert wird inhaltlich "definiert" (KGExperimente), worauf sich die Kritik am Begriff bezieht. evidenzorientiert und evidenzinformiert werden nur anhand der weniger starken Kritik abgegrenzt (also auf die Ebene der Rezeption/Kritik angesprochen). Was mit "heuristischer und rechenschafslegender Rolle" (also einem Kriterium, das nicht auf der Ebene der Forschungsdesigns (KGexperimente) oder der Kritik sondern auf der Ebene der Nutzung angesiedelt ist) gemeint ist, bleibt unscharf. Und ebenso bleibt im ungefÃ¤hren, ob evidenzorientiert und evidenzinformiert hier synonym sind oder nicht.-->

<!-- SB: Und noch was Formales: Ich habe nicht ganz verstanden, wann Begriffe kursiv und wann mit Â»Â« und wann beides eingesetzt wird. Ich habe nichts geÃ¤ndert, weil das ja auch von den Vorgaben des Bandes abhÃ¤ngen, aber mir ist es nicht klar geworden und hat es zwischendurch eher verwirrt (warum ist z.B. Cognitive Load Theory in plain? wann sind Â»Â« als direkte Zitate gemeint und wann als begriffshervorhebung usw.)? Kann da gerne ggf. nochmal einen entsprechenden Durchgang machen.  -->

In der deutschsprachigen bildungswissenschaftlichen Diskussion sind nach Bromme et al.[-@bromme2014b] zunÃ¤chst zwei verschiedene DiskussionsstrÃ¤nge bzgl. evidenzinformierter Entscheidungen im Bildungskontext unterscheidbar: Ein Diskussionsstrang beschÃ¤ftigt sich mit evidenzinformierten Entscheidungen in der Bildungspolitik und der andere mit evidenzinformierten Entscheidungen und Handlungen in der Bildungspraxis. In beiden Diskussionen werden Evidenz verschiedene Funktionen zugeschrieben. Bromme et al. [-@bromme2014b] etwa sprechen davon, dass Evidenz Ã¼ber ZustÃ¤nde informieren, Mechanismen erklÃ¤ren oder Interventionen evaluieren kann. GroÃŸ Ophoff et al. [@groÃŸophoff2023] wiederum unterscheiden eine konzeptuelle Nutzung (Â»*evidence allows focussing attention, provides new insights, challenges beliefs or reframes thinking*Â«, S. 02 <!-- SB: hier jeweils 0 vor der 2 lÃ¶schen oder ist das bewusst so?-->), instrumentelle Nutzung (Â»*identify or develop concrete measures to be taken*Â«, S. 02) und symbolische Nutzung (Â»*justif\[y\] or support of existing positions or established procedures*Â«, S. 02). <!-- SB: im Original nicht kursiv -> nur zitieren ohne kursiv oder die Kursivformatierung als eigene Hervorhebung kennzeichnen. Und inhaltich: soweit ich Janas Unterscheidung verstehe und auch den Kontext des Theorieteils des Papers, das Du zitierst, bezieht sich ihre Unterscheidung nur auf schulische Akteure, also Bildungspraxis, und nicht auf Bildungspolitik wie Bromme. So wie Bromme zu Beginn des Absatz eingefÃ¼hrt wird, liegt die Schlussfolgerung nahe, Janas Nutzungsformen auf Politik und Praxis zu beziehen. -->

## Potenzielle Wege zu einer gelingenden Wissenschaftskommunikation
UnabhÃ¤ngig vom Kontext und der Funktion evidenzinformierter Entscheidungen ist es plausibel anzunehmen, dass eine erfolgreiche Kommunikation von Evidenz zwischen Bildungswissenschaftler:innen/Fachdidaktiker:innen und den Akteuren im Bildungssystem eine notwendige Voraussetzung fÃ¼r das Gelingen evidenzinformierter Entscheidungen ist: Wird Evidenz fehlinterpretiert und erfolgt eine anschlieÃŸende Entscheidung kohÃ¤rent zu dieser Fehlinterpretation, wird die Wirkung dieser Entscheidung nicht die ErwÃ¼nschte sein.

```{r}
#| label: fig-AbbildungMoMa
#| apa-twocolumn: true
#| fig-cap: Daten einer (fiktiven) Studie, eine dazugehÃ¶rige Pressemitteilung und die Vorstellung einer Lehrkraft von den Daten # Daten der (fiktiven) Studie, Pressemitteilung und Vorstellung der Lehrkraft von den Daten
#| fig-height: 4
#| fig-width: 12
#| dev: "ragg_png"

library(tidyverse)
library(ggdist)
library(bayestestR)
library(hrbrthemes)
library(effectsize)
library(patchwork)
library(ggtext)
library(flextable)
library(geomtextpath)
library(colorspace)
library(brms)

set.seed(189)
data_reading_true <- 
    tibble(`Anzahl korrekt gelesener Worte pro Minute` = 
               round(c(rpois(500, 63), rpois(500, 61)), 1),
           Gruppe = c(rep("KI-Lesetutor", 500),
                      rep("Lautlesen", 500))) %>% 
    mutate(Gruppe = factor(Gruppe, 
                           levels = c("Lautlesen", "KI-Lesetutor")))

plot_true_data <- 
    ggplot(data_reading_true,
       aes(`Anzahl korrekt gelesener Worte pro Minute`, Gruppe)) +
    geom_dots(color = "#111111", fill = "#111111") +
    ylab("") +
    ggtitle("Daten", "der Studie") +
    theme_ipsum_rc()
        
plot_press <- 
    ggplot() +
    ggtitle("Ausschnitt", "der Pressemitteilung") +
    geom_richtext(
        data = data.frame(x = 1, y = 1, 
                          text = "In einer randomisierten Studie<br>mit *N* = 1001 DrittklÃ¤ssler:innen<br> zeigten diejenigen,<br>die tÃ¤glich 15 Minuten<br> mit dem KI-Vorlesetutor Ã¼bten,<br><b>signifikant bessere LeseflÃ¼ssigkeit</b><br>als DrittklÃ¤ssler:innen,<br>die tÃ¤glich 15 Minuten<br>(ohne KI-Tutor) laut lasen."),
        aes(x = x, y = y, label = text),
        size = 3,
        label.color = "black") +
    theme_ipsum_rc() +
    theme(panel.background = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank())

data_teacher <- 
    tibble(`Anzahl korrekt gelesener Worte pro Minute` = 
               round(c(distribution_poisson(500, 70), 
                       distribution_poisson(500, 61)), 1),
           Gruppe = c(rep("KI-Lesetutor", 500),
                      rep("Lautlesen", 500))) %>% 
    mutate(Gruppe = factor(Gruppe, 
                           levels = c("Lautlesen", "KI-Lesetutor")))

plot_teacher_representation <- 
    ggplot(data_teacher,
       aes(`Anzahl korrekt gelesener Worte pro Minute`, Gruppe)) +
    geom_dots(color = "#111111", fill = "#111111") +
    ylab("") +
    ggtitle("Interpretation", "einer Lehrkraft") +
    theme_ipsum_rc() +
    theme(axis.text.y = element_blank())


plot_true_data + plot_press + plot_teacher_representation +
    plot_layout(guides = "collect")

#cliffs_delta(`Anzahl korrekt gelesener Worte pro Minute` ~ Gruppe,
#             data = data_reading_true)
#cliffs_delta(`Anzahl korrekt gelesener Worte pro Minute` ~ Gruppe,
#             data = data_teacher)

    
```

Liest eine Lehrkraft etwa die (fiktive) Pressemitteilung in @fig-AbbildungMoMa, stellt sich die Ergebnisse wie in @fig-AbbildungMoMa rechts vor [@schmidt2023] und Ã¼berzeugt anschlieÃŸend ihre Schulleitung, diesen KI-Lesetutor zu beschaffen und schulweit einzusetzen, liegt hÃ¶chstwahrscheinlich dysfunktionales evidenzinformiertes Handeln vor. WÃ¤hrend die Forscher:innen mit *signifikant bessere LeseflÃ¼ssigkeit* zum Ausdruck bringen, dass ihre Daten unter der Annahme eines Nulleffekts unwahrscheinlich sind (signifikanter p-Wert), interpretiert die Lehrkraft diese Formulierung als Â»Unterschied **bedeutsamer GrÃ¶ÃŸe**Â«. Folglich schlussfolgert sie, dass es Sinn macht, Geld und Zeit in die Anschaffung und Implementation des KI-Lesetutors zu investieren, <!-- SB: einfÃ¼gen: weil sie den KI-Lesetutor fÃ¼r deutlich lernwirksamer hÃ¤lt als lautes Lesen. und dann mit Allerdings und Hauptsatz weitermachen--> obwohl etwa die Implementation von Lesetandems kostengÃ¼nstiger, weniger zeitaufwÃ¤ndig und lernwirksam gewesen wÃ¤re. <!-- SB: Mir unklar: meinst Du mit Lesetandems das gleiche oder was anderes als "lautlesen" im fiktiven Beispiel (es gibt auch Lautlesemethoden ohne Tandems.). Und als Kontext muss man wissen, was Lesetandems sind und dass sie lernwirksam sind, sonst ist der letzte Halbsatz eher verwirrend. WÃ¼rde ich ggf. noch ergÃ¤nzen, damit die Argumentation vollstÃ¤ndig ist. Und unabhÃ¤ngig davon wÃ¼rde ich die Reihenfolge im letzten Satz umstellen: "Lesetandems lernwirksam und zudem kostengÃ¼nstiger und weniger zeitaufwÃ¤ndig gewesen wÃ¤re. Denn es geht geht im fiktiven Bsp. ja erstmal um das Kriterium lernwirksamkeit (auch in der Studie) und dann nachgeordnet erst um Zeit und Kosten.  --> 

Die Forschung zur Wissenschaftskommunikation hat eine Reihe solcher potenziellen Problematiken aufgezeigt: Z.B. das soeben beschriebene Verwechseln von Inferenzstatistik und EffektstÃ¤rke [@schmidt2023], das automatische Annehmen starker Effekte, wenn keine EffektstÃ¤rken berichtet wurden [Practical Significance Bias, @michal2024], RÃ¼ckschaufehler [@masnick2009] oder die verzerrte EinschÃ¤tzung der Belastbarkeit von Befunden (z.B. das Ergebnis einer Laborstudie mit *N* = 56 mit groÃŸem Effekt und daher hoher statistischer Power) durch irrelevante Zahlen [z.B. StichprobengrÃ¶ÃŸe einer zuvor gelesenen Large-Scale-Studie, @bohrer2025].

Gleichzeitig liegt eine Reihe von Befunden vor, die implizieren, dass eine verbesserte Kommunikation von Evidenz an LehrkrÃ¤fte zu Zwecken evidenzinformierten Handelns vergleichsweise einfach umsetzbar ist <!-- SB: Ich verstehe und stimme zu, aber das ist schon auch ein Claim, den man kurz ausfÃ¼hren oder belegen kÃ¶nnte :-) -->. GrundsÃ¤tzlich lassen sich die bisherigen Befunde in angebotsseitige und nutzendenseitige AnsÃ¤tze unterscheiden, also in Interventionen, die die Auswahl und Darstellung der Evidenz optimieren mÃ¶chten und AnsÃ¤tze, die bei der Scientific und Statistical Literacy der LehrkrÃ¤fte ansetzen. <!-- SB: auch hier kÃ¶nnte man seitenweise BegriffsklÃ¤rung machen udn diskutieren, warum hier z.B. nicht data literacy kommt, obwohl unten die entsprechenden Beispielstudien kommen. Ist eine trade-off-Entscheidung, aber vielleicht ist es fÃ¼r distale Lesende einfacher, zu schreiben "AnsÃ¤tze, die bei den Kompetenzen der Lehrpersonen ansetzen, also z.B. ihren Kompetenzen im Umgang mit Forschungsergebnissen oder Daten-->

::: callout-caution
Gibt es diese Unterscheidung auch in der Literatur oder nur in unseren GesprÃ¤chen?

Antwort: Einen ersten Ansatz findest du bei BrÃ¼hwiler et al (2020). Das Modell ist zwar sehr umfassen und m.E. auch nicht ideal, aber als Referenz ein erster guter Ansatz. BrÃ¼hwiler, C., & Leutwyler, B. (2020). Praxisrelevanz von Forschung als gemeinsame Aufgabe von Wissenschaft und Praxis: Entwurf eines Angebots-Nutzungs-Modells. BzL - BeitrÃ¤ge zur Lehrerinnen- und Lehrerbildung, 38(1), 21â€“36. https://doi.org/10.36950/bzl.38.2020.9309

man kÃ¶nnte im weiteren Sinne auch auf Debiasing-Forschung verweisen, aber glaube die Referenz von BrÃ¼hwiler passt am besten
<!-- SB: in der DBDM Literatur gibt es die Unterscheidung konzeptuell, wenngleich nicht so explizit wie bei BrÃ¼hweilers Rahmenmodell. Z.B. in dem ganz frÃ¼hen Editorial Aufsatz von Kohler & Schrader (2004, inspiriert vom allgemeinen ANM) oder auch in dem Ãœberblicksartikel von Altricher et al aus dem HB Neue Steuerung (dort eher feedbacktheoretisch begrÃ¼ndet).   -->
:::

Zu zweiterem gehÃ¶ren Programme wie Â»Data TeamsÂ« [@schildkamp2015] <!-- SB: hab mich hier Ã¼ber die Zitation gewundert. Wenn es um das data team procedure an sich geht, wÃ¼rde ich  Schildkamp, K., Handelzalts, A., Poortman, C. L., Leusink, H., Meerdink, M., Smit, M., Ebbeler, J., & Hubers, M. D. (2018). The Data Teamâ„¢ Procedure: A Systematic Approach to School Improvement (K. Schildkamp, A. Handelzalts, C. L. Poortman, H. Leusink, M. Meerdink, M. Smit, J. Ebbeler, & M. D. Hubers, Eds.). Springer International Publishing. https://doi.org/10.1007/978-3-319-58853-7_9
zitieren, wenn um die Wirksamkeit, dann Poortman, C. L., & Schildkamp, K. (2016). Solving student achievement problems with a data use intervention for teachers. Teaching and Teacher Education, 60, 425â€“433. https://doi.org/10.1016/j.tate.2016.06.010
-->, welche durch ein umfÃ¤ngliches Set an vordefinierten Leitlinien und AktivitÃ¤ten versucht, konkrete schulische Probleme mit Hilfe von (oft eigens dafÃ¼r genierten) Daten zu lÃ¶sen, wobei meist 4-6 LehrkrÃ¤fte und Schulleiter:innen mit Bildungswissenschaftler:innen und Fachdidaktiker:innen kooperieren. <!-- es gibt auch research-practice partnerships die Ã¤hnlich angelegt sind, falls du das aufnehmen willst, sag gerne Bescheid, dann ergÃ¤nze ich die Quelle JA GERNE!--> Auch Kurz- [@merk2020] oder lÃ¤ngerfristig angelegte [@karst2024] Interventionen zur Anbahnung notwendiger Kompetenzen fÃ¼r evidenzinformiertes Handeln wie Graph Literacy<!-- SB: ggf. auch hier Begriff eher oder ergÃ¤nzend umschreiben: , die Interpretation von grafisch dargestellten Daten --> [@friel2001] oder Forschungskompetenz [@neuenschwander2005] sowie die konkrete UnterstÃ¼tzung fÃ¼r solches<!-- SB: woraus bezieht sich solches? Syntaktisch ambig. besser: evidenzinformiertes Handeln nochmal schreiben und keinen Platzhalter --> [@zotero-8935]<!-- SB: hier ggf noch deutlich machen, dass es um Clearing house geht, denn das sieht man anhand der Zitation im Text nicht. -->, kÃ¶nnen diesem Ansatz zugerechnet werden.

Angebotsseitige Versuche die Kommunikation von Evidenz zu verbessern, stammen aus verschiedensten sozialwissenschaftlichen Disziplinen: So wird z.B. in der Psychologie <!-- SB: Ich war mal bei Tino in einem Vortrag, ob Psychologie eine Naturwissenschaft sei ... kÃ¶nnte mir vorstellen, dass manche Psycholog:innen hier an die Decke gehen, denn die Formulierung hier ordnet sie klar als Sozialwissenschaft ein ;-) -->untersucht, welche algebraisch Ã¤quivalenten Formulierungen zu standardisierten EffektstÃ¤rken bei der Rezeption durch Laien adÃ¤quatere Vorstellungen induzieren [siehe @tbl-wisskommbsp, z.B. @grice2020]. In der Human-Computer-Interaction-Forschung werden (teils dynamische) Visualisierungstechniken entwickelt, um EffektstÃ¤rken und Inferential Uncertainty besser zu kommunizieren [z.B. @hullman2015; @zhang2023]. Die bildungswissenschaftliche Lehrerbildungsforschung sowie die Fachdidaktiken erproben innovative Formate fÃ¼r die Zielgruppe der LehrkrÃ¤fte [z.B. @schneider2024], was auch das Anliegen der vorliegenden Studie ist.

```{r}
#| label: tbl-wisskommbsp
#| tbl-cap: Beispiele fÃ¼r angebotsseitige Versuche verbesserter Kommunikation von Evidenz

library(gt)
library(timesaveR)
# Create table
tibble(`header1` = c("Standard-kommunikation", "Verbesserte Kommunikation"), 
       `Unterschied` = c("Die Leseleistung von SchÃ¼lerinnen und SchÃ¼lern in  (PISA 2022) sank um 28 Punkte und damit auf den Tiefststand.", "Die Leseleistungen von SchÃ¼lerinnen und SchÃ¼lern in Deutschland aus PISA 2018 und aus PISA 2022 Ã¼berlappen sich zu 88,9%, wobei der Mittelwert um 28 Punkte sank."),
       `Zusammenhang` = c("Der sozioÃ¶konomische Status klÃ¤rt 14% der Varianz der Mathematikleistung auf.", "Von 100 SchÃ¼lerinnen und SchÃ¼lern, die einen Ã¼berdurchschnittlichen sozioÃ¶konomischen Status haben, zeigen 69 eine Ã¼berdurchschnittliche Mathematikleistung.")) |>
  gt() %>% 
  gt_apa_style() %>% 
  cols_label(header1 = "") %>% 
  fmt_markdown(columns = everything()) %>% 
  opt_table_font(font = "Source Sans Pro")
    
```

# Die vorliegende Studie

In diesem Kontext untersucht die vorliegende Studie, inwiefern verbreitete Standardgrafiken zur Kommunikation der Entwicklung der Lesekompetenz in den deutschen Kohorten des Programme of International Student Assessment (PISA) Practical Significance Bias induzieren und ob dieser mit Grafiken eingedÃ¤mmt <!-- SB: s.o.: verringert oder vermindert  -->werden kann, bei deren Gestaltung theoretische und empirische Erkenntnisse der Wissenschaftkommunikation [siehe Abschnitt @sec-materialien] berÃ¼cksichtigt wurden.
<!-- SB: Ein etwas globalerer Kommentar: In der Studie wurden journalistische Grafiken verwendet und diese werden hier als "verbreitete Standardgrafiken" bezeichnet. Das suggeriert aus meiner Sicht an dieser Stelle auf der Basis des Theorieteils, wo es rein um Wissenschaftskommunikation durch Wissenschaft und gar nicht um Journalismus ging, dass es STandardgrafiken sind, die die Wissenschaft fÃ¼r die Wissenschaftskommunikation verwendet. Soweit ich das auf die Schnelle recherchieren konnte, gibt es solche Grafiken weder im allgemeinen OECD-Band noch in den entsprechenden deutschlandspezifischen Publikationen. Was es gibt, sind Liniendiagramme, wo jeweils Siginifikanz mit abgebildet ist (dotted vs durchgezogene Linien, aber auch keine Streuung oder EffektstÃ¤rke) und diese gibt es auch z.B im IQB Bildungstrend (aber auch dort gibt es keine Liniendiagramme wie in Tab. 2. Dh, wenn man es genau nimmt, wird hier journalistische Wissenschaftskommunikation, die auf der Basis der Publikationen von Wissenschaftlichen Institutionen (wenn man die OECD so bezeichnen will) herangezogen. Wird die Frage nach Stakeholdern/Akteursgruppen irgendwo noch aufgegriffen in der Diskussion? Z.B. dass die vorliegende Studie diese EinschrÃ¤nkung hat, aber das es trotzdem relevant ist, weil man davon ausgeht, dass LehrkrÃ¤fte damit in den Medien in BerÃ¼hrung kommen, daran evidenzorientiert handeln kÃ¶nnten und es deswegen probleamtisch und relevant ist o.Ã¤.? -->
## Methode

### Materialien {#sec-materialien}

In der Berichterstattung zu den Ergebnissen der PISA-2022-Kohorte wurden durch journalistische Medien zahlreiche Darstellungsformate gewÃ¤hlt, insbesondere Liniendiagramme <!-- ist es Ã¼blich im Deutschen den englischen Begriff zu verwenden? --> [siehe Tabelle @tbl-pisalinegraphs], was angesichts der Anlage des PISA als Trendstudie [@dÃ¶ring2016] konsequent erscheint.<!-- SB: Die Grafiken abzudrucken ist super, aber geht das vom Copyright her?-->

|  |  |  |
|------------------------|------------------------|------------------------|
| ![](img/sz.png){width="900"} | ![](img/tagessschau.jpg){width="900"} | ![](img/taz.jpeg){width="800"} |
| SÃ¼ddeutsche Zeitung -@volkert2023 | RBB -@rbb2023 | taz -@taz.de2023 |

: Verwendete Liniendiagramme in der Berichterstattung. {#tbl-pisalinegraphs}

Diese Abbildungen erlauben einen effizienten Vergleich der Mittelwerte sowohl Ã¼ber die Zeit als auch Variablen (hier: FÃ¤cher) hinweg. In solchen Grafiken ist jedoch die Bedeutsamkeit der Mittelwertsdifferenz nur bei bekannter Streuung interpretierbar: @fig-mwdiffstreuung zeigt jeweils die gleichen Mittelwertsdifferenzen von 508<!-- SB: In den Grafiken stand MW = 580, ich glaube, das war ein Tippfehler; ich hab die Beschriftung im Code geÃ¤ndert --> (PISA Lesen 2015) und 480 (PISA Lesen 2022).

```{r}
#| label: fig-mwdiffstreuung
#| apa-twocolumn: true
#| fig-cap: Illustration der UnabhÃ¤ngigkeit von Mittelwertsdifferenz und GrÃ¶ÃŸe des Effekts
#| fig-height: 4
#| fig-width: 7
#| dev: "ragg_png"

mwdiffstreuungdata <- 
    tibble(Jahr = c(rep(2015, 100), rep(2022, 100),
                    rep(2015, 100), rep(2022, 100)),
           Streuung = c(rep("Kleine Streuung", 200),
                        rep("Reale Streuung", 200)),
           Lesen = c(distribution_normal(100, 508, 20),
                     distribution_normal(100, 480, 20),
                     distribution_normal(100, 508, 100),
                     distribution_normal(100, 480, 100)))

effsizes <-
    mwdiffstreuungdata %>%
    nest_by(Streuung) %>%
    summarize(
        cohd = cohens_d(Lesen ~ Jahr, data = data)$Cohens_d,
        overlap = 2 * pnorm(-abs(cohd) / 2) %>% round(.,2)
    )

# ggplot(mwdiffstreuungdata, aes(Jahr, Lesen, group = Jahr)) + 
#     ggforce::geom_sina(shape = 1) +
#     ggtitle("Gleiche Mittelwertsdifferenzen", 
#             "unterschiedliche EffektstÃ¤rken") +
#     facet_wrap(~Streuung) + 
#     scale_x_continuous(breaks = c(2015, 2022)) +
#     theme_ipsum_rc()


ggplot(data.frame(x = c(0, 1000)), aes(x)) +
  geom_textline(
    stat = "function", 
    fun = dnorm,
    args = list(mean = 509, sd = 100),
    label = "MW = 508",
    size = 3, 
    fontface = 1, 
    hjust = .662, 
    vjust = 0,
    color = "purple"
  ) +
  stat_function(
    geom = "area", 
    fun = dnorm,
    args = list(mean = 509, sd = 100),
    fill = "#a01ff020",
    color="#ffffff00"
  ) +
  geom_textline(
    stat = "function", 
    fun = dnorm,
    args = list(mean = 480, sd = 100),
    label = "MW = 480",
    size = 3, 
    fontface = 1, 
    hjust = .331, 
    vjust = 0,
    color = "orange"
  ) +
  stat_function(
    geom = "area", 
    fun = dnorm,
    args = list(mean = 480, sd = 100),
    fill = "#ffa50020",
    color="#ffffff00"
  ) +
    annotate(
    "richtext", 
    x = 730, y = 0.0015, 
    label = "88% Ãœber-<br>lappung", 
    hjust = 0, vjust = .5, 
    fill = NA, label.color = NA,
    size = 2.8
  ) +
    geom_curve(
    aes(x = 730, y = 0.0015, xend = 500, yend = 0.0012),
    curvature = 0.3, # Positive for upward curve, negative for downward
    arrow = arrow(length = unit(0.052, "inches"), type = "closed"), 
    linewidth = .1
  ) +
  xlab("") +
  ylab("") +
  theme_ipsum_rc() +
  theme(axis.text.y = element_blank()) +
ggplot(data.frame(x = c(400, 600)), aes(x)) +
  geom_textline(
    stat = "function", 
    fun = dnorm,
    args = list(mean = 509, sd = 20),
    label = "MW = 508",
    size = 3, 
    fontface = 1, 
    hjust = .676, 
    vjust = 0,
    color = "purple"
  ) +
  stat_function(
    geom = "area", 
    fun = dnorm,
    args = list(mean = 509, sd = 20),
    fill = "#a01ff020",
    color="#ffffff00"
  ) +
  geom_textline(
    stat = "function", 
    fun = dnorm,
    args = list(mean = 480, sd = 20),
    label = "MW = 480",
    size = 3, 
    fontface = 1, 
    hjust = .3, 
    vjust = 0,
    color = "orange"
  ) +
  stat_function(
    geom = "area", 
    fun = dnorm,
    args = list(mean = 480, sd = 20),
    fill = "#ffa50020",
    color="#ffffff00"
  ) +
    annotate(
    "richtext", 
    x = 550, y = 0.008, 
    label = "48% Ãœber-<br>lappung", 
    hjust = 0, vjust = .5, 
    fill = NA, label.color = NA,
    size = 2.8
  ) +
    geom_curve(
    aes(x = 550, y = 0.008, xend = 500, yend = 0.006),
    curvature = 0.3, # Positive for upward curve, negative for downward
    arrow = arrow(length = unit(0.052, "inches"), type = "closed"), 
    linewidth = .1
  )+
  xlab("") +
  ylab("") +
  theme_ipsum_rc() + 
  theme(axis.text.y = element_blank())
```

Das AusmaÃŸ der Bedeutsamkeit dieses (gleichen) Mittelwertsunterschieds entsteht aber erst durch die Streuung der Daten um diesen Mittelwert herum. Weil die Variablen im rechten Teil der Abbildung kaum streuen, ist die Ãœberlappung der beiden Gruppen gering (`{r} effsizes$overlap[1]*100`%, groÃŸer Effekt), wÃ¤hrend die groÃŸe Ãœberlappung im linken Teil (`{r} effsizes$overlap[2]*100`%, kleiner Effekt) durch die groÃŸe Streuung zustande kommt. Die Abbildungen in [Tabelle @tbl-pisalinegraphs] sagen also nicht nur nichts Ã¼ber die Bedeutsamkeit der Mittelwertsunterschiede aus. Die nicht dargestellte Varianz induziert mÃ¶glicherweise auch eine wahrgenommene groÃŸe Bedeutsamkeit der Mittelwertsdifferenz [@kale2020].

|                                |                                        |
|--------------------------------|----------------------------------------|
| ![](img/taz.jpeg){width="400"} | ![](img/geomtextline.png){width="363"} |

: Verwendete Stimuli {#tbl-materials}

Daher wurden vorliegend neben Liniendiagrammen auch Ã¼berlappende Verteilungskurven verwendet. Um diese barriereÃ¤rmer zu gestalten, wurde bei der Farbgebung auf hinreichenden Kontrast bei den prÃ¤valenten Sehbehinderungen geachtet [@garnier2023]. Um eine unnÃ¶tige ArbeitsgedÃ¤chtnisbelastung zu vermeiden, wurde die Legende direkt in die Grafik integriert [@franconeri2021].

### Design, Stichprobe und Instrument

```{r}
#| label: dataimport
data <- 
  read_csv("data/data_cummunication_PISA.csv") %>% 
  mutate(
      POS = case_when(
        is.na(G003_01) ~ G004_01,
        is.na(G004_01) ~ G003_01,
        is.na(G003_01) & is.na(G003_01) ~ NA),
      POS = ifelse(POS %in% c(-1,-9), NA, POS),
      POS0510 = POS/max(POS, na.rm = T)/2 + 0.5,
      Stimulus = as.factor(case_when(
        ZG01 == 1 ~ "Originalgrafik taz",
        ZG01 == 2 ~ "Ãœberlappungsgrafik"))
  )
        
```
<!-- SB:Ich habe im folgenden fÃ¼r die beiden Grafiken/Stimuli konsequent die begriffe eingesetzt, die du hier als erstes im Absatz bzw. davor verwendet hast, also Liniendiagramm und Ã¼berlappende Verteilungskurve. Habe das auch in den Grafiken geÃ¤ndert, damit alles zusammenpasst.  -->
In einem <!-- einfachen - wÃ¼rde ich lÃ¶schen --> Between-Person Design wurde *N* = `{r} nrow(data)` Studierenden in BachelorstudiengÃ¤ngen des Primar- und Sekundarstufenlehramtes randomisiert entweder das Liniendiagramm oder die Ã¼berlappende Verteilungskurve (vgl. @tbl-materials ) <!-- eine der beiden in @tbl-materials dargestellten Abbildungen--> gezeigt. AnschlieÃŸend wurden sie mit folgenden Stimulus aufgefordert, die EffektstÃ¤rke einzuschÃ¤tzen: "*Basierend auf dieser Grafik: Wie hoch schÃ¤tzen (exakte Antwort nicht mÃ¶glich) Sie die Wahrscheinlichkeit ein, dass eine zufÃ¤llig gezogene SchÃ¼lerin oder ein zufÃ¤llig gezogener SchÃ¼ler aus dem Jahr 2022 im Lesen schlechter abschneidet als eine zufÃ¤llig gezogene SchÃ¼lerin oder SchÃ¼ler aus dem Jahr 2015?*". Beantwortet wurde diese Frage mit einem Schieberegler, dessen Enden <!-- wie folgt beschriftet waren:--> mit "*50% (beide Gruppen gleich)*" und "*100%* *(maximaler Effekt)*" beschriftet waren. Diese Erfassung der wahrgenommenen EffektstÃ¤rke als Â»Probability of SuperiorityÂ« ist in der Human-Computer-Interaction-Forschung verbreitet und gilt als valide [@brooks2014; @kim2022], wenngleich die Operationalisierung als Schieberegeler unklar lÃ¤sst, inwiefern bei der Beantwortung tatsÃ¤chlich eine Elaboration der Ãœberlappung vorgenommen wird oder die Teilnehmenden eher wie bei einem Likert-Item vorgehen. <!-- m.E. mÃ¼sste dieser Punkt nÃ¤her ausgefÃ¼hrt werden oder gelÃ¶scht... so finde ich ihn ohne Zusatzinfos schwer nachvollziehbar @SARAH: DU AUCH? SB: Ja, stimme voll zu.-->

### Statistische Analyse

Die abhÃ¤ngige Variable Â»Wahrgenommene EffektstÃ¤rkeÂ« (operationalisiert als Probability of Superiority) ist per Design auf das geschlossene Intervall [0,5; 1] beschrÃ¤nkt und zeigt empirisch BimodalitÃ¤t (siehe @fig-plotresults). Um diesen UmstÃ¤nden in der inferenzstatistischen Modellierung Rechnung zu tragen, wurden Bayesianische Mixture Regressionsmodelle fÃ¼r zwei trunkierte Normalverteilungen [@frischkorn2023] in der probabilistischen Sprache Stan [@standevelopmentteam2024] mithilfe des R-Pakets {brms} [@bÃ¼rkner2017] geschÃ¤tzt.

```{r}
#| label: betareg
#| cache: true
#
# mod <- brm(
#     bf(POS0510 | trunc(lb = .5, ub = 1) ~ Stimulus),
#     data = data,
#     cores = 4,
#     iter = 100000,
#     seed = 5,
#     control = list(adapt_delta = 0.95),
#     family = mixture(gaussian(), gaussian()),
#     init = 0,
#     prior = c(
#         prior(normal(0.6, .6), Intercept, dpar = mu1),
#         prior(normal(.9, .6), Intercept, dpar = mu2)
#     )
# )
#save(mod, file = "data/mod.RData")
load("data/mod.RData")
hyp <- hypothesis(
  mod,
  "theta1 * b_mu1_StimulusÃœberlappungsgrafik + (1-theta1) *
                         b_mu2_StimulusÃœberlappungsgrafik < 0",
  class = NULL
)

manwhit <- wilcox.test(POS0510 ~ Stimulus, data = data)
cliffd <- cliffs_delta(POS0510 ~ Stimulus, data = data)$r_rank_biserial[1]
cohd <-  (2 * cliffd) / sqrt(1 - cliffd^2)
u3 <-  pnorm(cohd)
overlap <-  2*pnorm(-abs(cohd)/2)

# loop weniger gebiased effsize

ueberlappung_weniger_gebiased <- logical(0)

for(i in 1:10000){
  selected_original <- 
    data %>% 
    select(POS0510, Stimulus) %>% 
    filter(Stimulus == "Originalgrafik taz") %>% 
    na.omit() %>% 
    sample_n(1) %>% 
    pull(POS0510)
  
    selected_ueberlappung <- 
    data %>% 
    select(POS0510, Stimulus) %>% 
    filter(Stimulus == "Ãœberlappungsgrafik") %>% 
    na.omit() %>% 
    sample_n(1) %>% 
    pull(POS0510)
    
    ueberlappung_weniger_gebiased[i] <- 
      abs(selected_ueberlappung - .58) < abs(selected_original - .58)
    
}
```

### Ergebnisse

Die Inspektion des Marcov-Chain-Monte-Carlo-Sampling-Prozesses zeigte eine zufriedenstellende QualitÃ¤t bzgl. der Konvergenz $(\hat{R} < 1.01)$ und der effektiven Sampling Size [$ESS_{Bulk} > 1000 < ESS_{Tail}$, @vehtari2021prefix]. <!-- versteht man das ohne Vorwissen? SICHER NICHT ğŸ˜. ABER WEGLASSEN FÃ„NDE ICH SCHADE UND ERKLÃ„REN OVERKILL ğŸ¤·ğŸ½â€â™‚ï¸. WAS MEINST DU @SARHvielleicht nicht erklÃ¤ren, aber einen natÃ¼rlichsprachlichen Satz einfÃ¼gen, was es bedeutet a la SchÃ¤tzung des Modells funktioniert anhand gÃ¤ngiger Indikatoren   -->
<!-- SB: Stimme dem Kommentar zu den Farben in der Ergebnisgrafik zu-->
```{r}
#| label: fig-plotresults
#| apa-twocolumn: true
#| fig-cap: GeschÃ¤tze EffektstÃ¤rke (Probability of Superiority) nach Stimulus. Beide Gruppen zeigen einen sehr deutlichen Practical Significance Bias (Abstand von Median und wahrem Wert).  ## ich habe mich gerade gefragt, ob es vielleicht sinnvoll ist die farbliche Encodierung in Abbildung 3 anders zu gestalten als in Tabelle 3. 
#| fig-height: 4
#| fig-width: 9
#| dev: "ragg_png"

data_results <- data %>% 
  select(G003_01, G004_01) %>% 
  gather(Stimulus, `Probability of Superiority`, G003_01, G004_01) %>%
  filter(`Probability of Superiority` > 0) %>% 
  na.omit() %>% 
  mutate(
    Stimulus = case_when(
      Stimulus == "G003_01" ~ "Liniendiagramm",
      Stimulus == "G004_01" ~ "Ã¼berlappende Verteilungskurve"
    ),
    `Probability of Superiority` = (`Probability of Superiority` - 50) /
      200 + .75)

pal <- c("#FF8C00", "#A034F0")

add_sample <- function(x) {
  return(c(y = max(x) + .025, 
           label = length(x)))
}
data_results |> 
  ggplot(aes(x = fct_rev(Stimulus), y = `Probability of Superiority`)) + 
    # add true value
    geom_hline(yintercept = .58) +
  ggdist::stat_halfeye(
    aes(color = Stimulus,
        fill = after_scale(lighten(color, .5))),
    adjust = .5, 
    width = .75, 
    .width = 0,
    justification = -.4, 
    point_color = NA
  ) +
  geom_boxplot(
    aes(color = stage(Stimulus, after_scale = darken(color, .1, space = "HLS")),
        fill = after_scale(desaturate(lighten(color, .8), .4))),
    width = .32, 
    outlier.shape = NA
  ) +
  geom_point(
    aes(color = stage(Stimulus, after_scale = darken(color, .1, space = "HLS"))),
    fill = "white",
    shape = 21,
    stroke = .4,
    size = 2,
    position = position_jitter(seed = 1, width = .12)
  ) + 
  geom_point(
    aes(fill = Stimulus),
    color = "transparent",
    shape = 21,
    stroke = .4,
    size = 2,
    alpha = .3,
    position = position_jitter(seed = 1, width = .12)
  ) + 
  stat_summary(
    geom = "text",
    fun = "median",
    aes(label = format(round(after_stat(y), 2), nsmall = 2),
        color = stage(Stimulus, after_scale = darken(color, .1, space = "HLS"))),
    family = "Roboto Mono",
    fontface = "bold",
    size = 4.5,
    vjust = -3.5
  ) +
  stat_summary(
    geom = "text",
    fun.data = add_sample,
    aes(label = paste("n =", after_stat(label)),
        color = stage(Stimulus, after_scale = darken(color, .1, space = "HLS"))),
    family = "Roboto Condensed",
    size = 4,
    hjust = 0
  ) +
  coord_flip(xlim = c(1.2, NA), clip = "off") +
  scale_color_manual(values = pal, guide = "none") +
  scale_fill_manual(values = pal, guide = "none") +
  labs(
    x = NULL,
    y = "Probability of Superiority"
  ) +
    
    # caption of true value
     
    annotate(
    "richtext", 
    y = .5, x = 2.9, 
    label = "wahrer<br>Wert", 
    hjust = 0, vjust = .5, 
    fill = NA, label.color = NA,
    size = 3.2
  ) +
    geom_curve(
    aes(y = .53, x = 2.8, yend = .566, xend = 2.6),
    curvature = 0.3, # Positive for upward curve, negative for downward
    arrow = arrow(length = unit(0.052, "inches"), type = "closed"), 
    linewidth = .1
  )+

  
  theme_minimal(base_family = "Roboto Condensed", base_size = 15) +
  theme(
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_blank(),
    axis.ticks = element_blank(),
    axis.text.x = element_text(family = "Roboto Mono"),
    axis.text.y = element_text(
      color = rev(darken(pal, .1, space = "HLS")), 
      size = 15
    ),
    axis.title.x = element_text(margin = margin(t = 10),
                                size = 16),
    plot.title = element_markdown(face = "bold", size = 21),
    plot.subtitle = element_text(
      color = "grey40", hjust = 0,
      margin = margin(0, 0, 20, 0)
    ),
    plot.title.position = "plot",
    plot.caption = element_markdown(
      color = "grey40", lineheight = 1.2,
      margin = margin(20, 0, 0, 0)),
    plot.margin = margin(15, 15, 10, 15)
  )
```


Die MedianeinschÃ¤tzung der Probability of Superiority lag in beiden Gruppe deutlich Ã¼ber dem wahren Wert (Liniendiagramm .80, Ã¼berlappende Verteilungsgrafik .73). Dieser Unterschied in der EinschÃ¤tzung entspricht einer Ãœberlappung von `{r} round(overlap*100, 2)`% (Cliff's *d* = `{r} round(cliffd)`) <!-- SB:hier steht im html cliffs d = 0, da passt irgendwas nicht-->oder anders ausgedrÃ¼ckt: Legt man 100 mal einem:einer Studierenden das Liniendiagramm und einem:einer Studierenden die Ã¼berlappende Verteilungsgrafik vor, schÃ¤tzt `{r} round(mean(ueberlappung_weniger_gebiased),2)*100`mal die:der Studierende mit der Ã¼berlappenden Verteilungsgrafik den Effekt weniger verzerrt ein. Die Inferenzstatistik fÃ¼r diesen Unterschied ist mit einer Evidence Ratio von `{r} round(hyp$hypothesis$Evid.Ratio, 1)` klar konklusiv: Die vorliegenden Daten sind 14,8-fach wahrscheinlicher unter der Annahme, dass der Mittelwert in der geschÃ¤tzten EffektstÃ¤rke in der Gruppe mit der Ã¼berlappenden Verteilungsgrafik niedriger ist als unter der Annahme, dass beide gleich sind.

# Diskussion

## Literatur
